{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4f0da5bd-67bf-4d04-9516-ee3c0b505224",
      "cell_type": "markdown",
      "source": "Handling Missing Data using SimpleImputer",
      "metadata": {}
    },
    {
      "id": "3662b8be-aba4-4c71-9b5b-a9980b3954a5",
      "cell_type": "code",
      "source": "from sklearn.impute import SimpleImputer\nimport numpy as np\n\ndata = np.array([[1,2,np.nan],\n                [4,np.nan,6],\n                [np.nan,8,9]\n                ])\n\nimputer = SimpleImputer(strategy='mean') #other strategies --> constant [strategy = 'constant', fill_value = x], median,\n\nimputedData = imputer.fit_transform(data)\n\nprint(data)\nprint(imputedData)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[ 1.  2. nan]\n [ 4. nan  6.]\n [nan  8.  9.]]\n[[1.  2.  7.5]\n [4.  5.  6. ]\n [2.5 8.  9. ]]\n"
        }
      ],
      "execution_count": 9
    },
    {
      "id": "36b58890-97c8-41a3-b588-a28f812d7763",
      "cell_type": "markdown",
      "source": "Handling missing data using KNN imputer",
      "metadata": {}
    },
    {
      "id": "e6ef47c0-e888-48f6-a76e-a702b97ea717",
      "cell_type": "code",
      "source": "from sklearn.impute import KNNImputer\nimport numpy as np\n\ndata = np.array([[1,2,np.nan],\n                [4,np.nan,6],\n                [np.nan,8,9],\n                 [4,np.nan,2]\n                ])\n\nknnImputer = KNNImputer(n_neighbors=2)\n\nimputedData = knnImputer.fit_transform(data)\n\nprint(data)\nprint(imputedData)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[ 1.  2. nan]\n [ 4. nan  6.]\n [nan  8.  9.]\n [ 4. nan  2.]]\n[[1.  2.  4. ]\n [4.  5.  6. ]\n [2.5 8.  9. ]\n [4.  5.  2. ]]\n"
        }
      ],
      "execution_count": 14
    },
    {
      "id": "4dc5bc99-5ac6-4b0c-932f-a10476f0c154",
      "cell_type": "markdown",
      "source": "Using fit() and transform with MaxMinScaler ",
      "metadata": {}
    },
    {
      "id": "ed047c50-7598-4085-9e35-7ef83aa9cb22",
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\ndata = np.array([[10,20], [15,30], [25,40], [30,60]\n                ])\nscaler = MinMaxScaler()\nscaler.fit(data)\n\nscaled_data = scaler.transform(data)\nprint(scaled_data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0.   0.  ]\n [0.25 0.25]\n [0.75 0.5 ]\n [1.   1.  ]]\n"
        }
      ],
      "execution_count": 21
    },
    {
      "id": "28e4cf36-4a8a-44b8-9af3-460496360bf2",
      "cell_type": "markdown",
      "source": "Feature Extration using CountVectorizer",
      "metadata": {}
    },
    {
      "id": "caf4fe83-dd95-4398-895a-a65208613778",
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\ndocuments = [\n    \"Your Service is very very bad\",\n    \"Tcs is service based company.\",\n    \"You work in bad service company.\"\n]\ncount_vectorizer = CountVectorizer()\n\ncount_matrix = count_vectorizer.fit_transform(documents)\n\nprint(\"Vocabulary:\", count_vectorizer.vocabulary_)\nprint(count_matrix.toarray())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Vocabulary: {'your': 10, 'service': 5, 'is': 4, 'very': 7, 'bad': 0, 'tcs': 6, 'based': 1, 'company': 2, 'you': 9, 'work': 8, 'in': 3}\n[[1 0 0 0 1 1 0 2 0 0 1]\n [0 1 1 0 1 1 1 0 0 0 0]\n [1 0 1 1 0 1 0 0 1 1 0]]\n"
        }
      ],
      "execution_count": 22
    },
    {
      "id": "5ae06a33-a12c-4f09-bcb9-58a16583661d",
      "cell_type": "markdown",
      "source": "Feature Extraction",
      "metadata": {}
    },
    {
      "id": "a3efb640-abdc-4c0c-a3cf-7b69afa60ffd",
      "cell_type": "code",
      "source": "from sklearn.feature_extraction import DictVectorizer\n\ndata=[\n    {'age':30, 'gender': 'female'},\n    {'age': 12, 'gender': 'male'},\n    {'age': 35, 'gender': 'male'} \n]\n\nvectorizer = DictVectorizer()\n\nfeatures_matrix = vectorizer.fit_transform(data) \n\nfeature_names = vectorizer.get_feature_names_out()\nprint (feature_names)\nprint (features_matrix)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['age' 'gender=female' 'gender=male']\n<Compressed Sparse Row sparse matrix of dtype 'float64'\n\twith 6 stored elements and shape (3, 3)>\n  Coords\tValues\n  (0, 0)\t30.0\n  (0, 1)\t1.0\n  (1, 0)\t12.0\n  (1, 2)\t1.0\n  (2, 0)\t35.0\n  (2, 2)\t1.0\n"
        }
      ],
      "execution_count": 31
    },
    {
      "id": "a9214b4e-f0d7-4a89-9bc4-d9aaf3b24dac",
      "cell_type": "markdown",
      "source": "Encoding Category Variables \nLabel Encoding",
      "metadata": {}
    },
    {
      "id": "c5a4309f-1e9e-4c48-ab07-3077d703137a",
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\n\ndata = ['red', 'blue', 'green', 'blue', 'red']\nlabel_encoder = LabelEncoder()\nencoded_data = label_encoder.fit_transform(data)\n\nprint(encoded_data)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[2 0 1 0 2]\n"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "f61bd1f8-277c-4bc3-89f7-0f0f0505b5c5",
      "cell_type": "markdown",
      "source": "One-Hot Encoding",
      "metadata": {}
    },
    {
      "id": "5fbc2ec8-3c33-4880-b94d-dfcfcf23d006",
      "cell_type": "code",
      "source": "from sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# Sample data\ndata = np.array(['red', 'blue', 'green', 'blue', 'red']).reshape(-1, 1)\n\n# Initialize OneHotEncoder\nonehot_encoder = OneHotEncoder(sparse_output=False)\n\n# Fit and transform the data\nencoded_data = onehot_encoder.fit_transform(data)\n\nprint(encoded_data)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 0. 1.]]\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "48a829a3-565b-4c1b-a82c-be55b1818a69",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}